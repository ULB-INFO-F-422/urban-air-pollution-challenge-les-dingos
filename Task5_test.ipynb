{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f51e4af1-f39f-40cf-8f70-2ece0a74d81e",
   "metadata": {},
   "source": [
    "# INFO-F-422 Project 23-24 : Zindi: - Urban Air Pollution Challenge - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd5f498-db42-4790-870e-b62a632ec13b",
   "metadata": {},
   "source": [
    "## Description of the Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21a2e5e-59c7-43c9-a28c-a0ece6c2ac61",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "639e4e44-c952-41e8-ab9d-4fae3fc23264",
   "metadata": {},
   "source": [
    "### Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77c0db5-7273-4323-b1f5-b636137fcc53",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e82445a0-461f-4e08-b820-336404535108",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9afae49-b9f5-4e96-b6aa-66129293a74b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf2208c3-b278-468a-a621-bb411659796e",
   "metadata": {},
   "source": [
    "### scoring metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad06d0ec-8ea9-4560-9375-5bf434d6a3ea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bf2cfe18-ddb6-4322-b748-99a89e167e50",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d00a1c4-75da-4ef8-a4a7-fd3c9d587ce0",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16551485-60b3-48a6-85ab-c480e24b7f1a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(dplyr)\n",
    "library(randomForest)\n",
    "library(ggplot2)\n",
    "library(RSNNS)\n",
    "library(e1071)\n",
    "library(xgboost)\n",
    "library(keras)\n",
    "library(repr)\n",
    "library(caret)\n",
    "library(lubridate)\n",
    "library(VIM)\n",
    "library(lightgbm)\n",
    "\n",
    "options(repr.matrix.max.cols=500, repr.matrix.max.rows=200)\n",
    "#set.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8bbcd2-6c54-48d5-aa70-6a115065909e",
   "metadata": {},
   "source": [
    "### 1. Pipeline\n",
    "This section will contain a few functions that can be called to modify, complete or create new features.`\n",
    "\n",
    "These Functions can then after be called easilly to try different combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49405ff-7a5f-45bb-92f3-f3afd69528eb",
   "metadata": {},
   "source": [
    "#### Data importation & Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c167b11-2e4a-4ec1-a0cc-1282f6b3f6e3",
   "metadata": {},
   "source": [
    "2 simple functions that helps getting a clean data easilly for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4908415b-2aab-4325-a1d4-3db387934d09",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "get_train_data <- function() {\n",
    "    train_df <- read.csv(\"Train.csv\")\n",
    "    train_df <- train_df %>% \n",
    "        select(-\"target_min\", -\"target_max\",-\"target_variance\",-\"target_count\")\n",
    "    return(train_df)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5753a00-2be1-4005-afbc-e63edca7c6ce",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "get_test_data <- function() {\n",
    "    train_df <- read.csv(\"Test.csv\")\n",
    "    return(train_df)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2c0307-cb37-4c96-8994-687472cfe836",
   "metadata": {},
   "source": [
    "#### Missing value imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15423a0a-59d2-45c5-9ffd-962a3f4ee892",
   "metadata": {},
   "source": [
    "Different methods that can be applied to the data in order avoid keeping empty data in the datasets.\n",
    "1. This method simply deletes all columns containing nan's and keeps only the ones that are complete. This method is quite drastic and reduces a lot our dataset.\n",
    "2. The second method will tranform all the nan's in the data by the mean of that column. This allows to keep all the original data.\n",
    "3. The third method will tranform all the nan's in the data by the median of that column. This allows to keep all the original data.\n",
    "4. The fourth method will tranform all the nan's in the data by the median of that column but grouped for each station. alowing us to keep all the data and also laverage the information of the median of the area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93bd68e0-0a4b-453e-a31d-027e0415bae0",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Drop na's\n",
    "drop_na <- function(data) {\n",
    "    data_clean <- data[, colSums(is.na(data)) == 0]\n",
    "    return(data_clean)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ca2c9d8-b6ec-46b3-b3a2-614304fcecae",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Replace na's by mean\n",
    "na_to_mean <- function(data) {\n",
    "    data_clean <- data %>%\n",
    "        mutate(across(everything(), ~ifelse(is.na(.), mean(., na.rm = TRUE), .)))\n",
    "    return(data_clean)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78b0383f-a724-492b-8b2f-a8589103f211",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Replace na's by median\n",
    "na_to_median <- function(data) {\n",
    "    data_clean <- data %>%\n",
    "        mutate(across(everything(), ~ifelse(is.na(.), median(., na.rm = TRUE), .)))\n",
    "    return(data_clean)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a76e659f-570c-462c-8d7b-c3ef80b65c9a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Replace NA's by the median by Place_ID\n",
    "na_to_median_by_location <- function(data) {\n",
    "    # Step 1: Replace NA's within each Place_ID group\n",
    "    data_clean <- data %>%\n",
    "        group_by(Place_ID) %>%\n",
    "        mutate(across(where(is.numeric), ~ifelse(is.na(.), median(., na.rm = TRUE), .))) %>%\n",
    "        ungroup()\n",
    "\n",
    "    # Step 2: Calculate global medians for each numeric column\n",
    "    global_medians <- data %>%\n",
    "        summarize(across(where(is.numeric), median, na.rm = TRUE)) %>%\n",
    "        unlist()\n",
    "    \n",
    "    # Step 3: Replace remaining NA's with global medians\n",
    "    data_clean <- data_clean %>%\n",
    "        mutate(across(where(is.numeric), ~ifelse(is.na(.), global_medians[cur_column()], .)))\n",
    "\n",
    "    return(data_clean)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f417168b-0b59-441b-8e21-6afbd950ca53",
   "metadata": {},
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11abd317-b664-48d5-b249-44500128d657",
   "metadata": {},
   "source": [
    "That function will normalize the whole dataset pet column. (the function scale will also be used later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e24d1d11-d12a-4b08-b833-bf50a39c3578",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#Function that will normalize all the columns\n",
    "normalize <- function(x) {\n",
    "  (x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9eda2a-e79f-4fab-ad7b-8ad5aa990537",
   "metadata": {},
   "source": [
    "#### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d95250e8-da5f-4738-b793-ea6d9df5fdb6",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Add columns for day, mounth, year, day of the week and if it is weekend or not.\n",
    "add_time <- function(data) {\n",
    "    data <- data %>%\n",
    "        mutate(day = day(Date),\n",
    "               month = month(Date),\n",
    "               day_of_week = wday(Date),\n",
    "               s_weekend = as.integer(wday(Date) %in% c(6, 7)))\n",
    "    data <- data %>%\n",
    "        group_by(Place_ID) %>%\n",
    "        mutate(placeID_freq = n()) %>%\n",
    "        ungroup()\n",
    "\n",
    "    return(data)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76fc1f0f-48b1-4fca-99b5-040d2903ee89",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Function to add lag, lead of all the columns enabeling it to see what was before and after\n",
    "add_lag_lead <- function(data, days) {\n",
    "    # Features: Excluding specific columns from the dataset\n",
    "    features <- setdiff(names(data), c(\"Date\", \"target_count\", \"target_min\", \"Place_ID X Date\", \"target_variance\", \"target_max\", \"Place_ID.X.Date\", \"target\"))\n",
    "    \n",
    "    numeric_features <- sapply(data, is.numeric)\n",
    "    features <- names(numeric_features[numeric_features == TRUE])\n",
    "    features <- setdiff(features, c(\"target\", \"Place_ID.X.Date\", \"Date\"))\n",
    "    \n",
    "    # Wrap operations in a group_by() without arranging\n",
    "    data <- data %>%\n",
    "        group_by(Place_ID) %>%\n",
    "        mutate(across(all_of(features), ~lag(.x, 1), .names = \"prev_{.col}_1\"),\n",
    "               across(all_of(features), ~lead(.x, 1), .names = \"next_{.col}_1\")) %>%\n",
    "        ungroup()  # Return to regular data frame operation without groups\n",
    "    \n",
    "    # Now create the difference features\n",
    "    for (i in 1:days) {\n",
    "        # Creating difference features for lag\n",
    "        data <- data %>%\n",
    "            group_by(Place_ID) %>%\n",
    "            mutate(across(all_of(features), ~. - lag(., i), .names = paste0(\"prev_{.col}_\", i+1))) %>%\n",
    "            ungroup()\n",
    "        \n",
    "        # Creating difference features for lead\n",
    "        data <- data %>%\n",
    "            group_by(Place_ID) %>%\n",
    "            mutate(across(all_of(features), ~. - lead(., i), .names = paste0(\"next_{.col}_\", i+1))) %>%\n",
    "            ungroup()\n",
    "    }\n",
    "    \n",
    "    # Replace NA values in numeric columns with 0\n",
    "    numeric_columns <- sapply(data, is.numeric)\n",
    "    data[numeric_columns] <- lapply(data[numeric_columns], function(x) replace(x, is.na(x), 0))\n",
    "    \n",
    "    return(data)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba44773-9e35-4185-86e2-cd6d9ea86484",
   "metadata": {},
   "source": [
    "#### Divide train / validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "018c576a-1731-4488-9166-c348719dfacc",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# randomise stations in train and val by grouping the Place_ID's\n",
    "# This allows to not overfit with the test data that doesn't contain similar Place_ID's as the training data\n",
    "get_train_val <- function(data, rep) {\n",
    "    unique_place_ids <- unique(data$Place_ID)\n",
    "    shuffled_place_ids <- sample(unique_place_ids)\n",
    "    unique_place_ids <- unique(data$Place_ID)\n",
    "    shuffled_place_ids <- sample(unique_place_ids)\n",
    "    num_train <- round(length(shuffled_place_ids) * rep)\n",
    "    train_ids <- shuffled_place_ids[1:num_train]\n",
    "    val_ids <- shuffled_place_ids[(num_train + 1):length(shuffled_place_ids)]\n",
    "    train <- data[data$Place_ID %in% train_ids, ] %>% \n",
    "      select(-\"Place_ID\")\n",
    "    val <- data[data$Place_ID %in% val_ids, ] %>% \n",
    "      select(-\"Place_ID\")\n",
    "    return(list(train = train, val = val))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38c43f0-4a8b-4a30-b3ed-5e11afabb4ea",
   "metadata": {},
   "source": [
    "#### Configuration grid example\n",
    "This allows to decide for each test which missing value imputation, normalization, feature engeneering and train_val repartition to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54e1a69c-e785-4303-a658-1822f905c8ea",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"\u001b[1m\u001b[22mThere was 1 warning in `summarize()`.\n",
      "\u001b[1m\u001b[22m\u001b[36mℹ\u001b[39m In argument: `across(where(is.numeric), median, na.rm = TRUE)`.\n",
      "Caused by warning:\n",
      "\u001b[1m\u001b[22m\u001b[33m!\u001b[39m The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\n",
      "Supply arguments directly to `.fns` through an anonymous function instead.\n",
      "\n",
      "  # Previously\n",
      "  across(a:b, mean, na.rm = TRUE)\n",
      "\n",
      "  # Now\n",
      "  across(a:b, \\(x) mean(x, na.rm = TRUE))\"\n"
     ]
    }
   ],
   "source": [
    "train = get_train_data()\n",
    "test = get_test_data()\n",
    "data <- bind_rows(train, test)\n",
    "data <- na_to_median_by_location(data)\n",
    "data <- add_time(data)\n",
    "data <- add_lag_lead(data,10)\n",
    "features <- setdiff(names(data), c(\"Date\", \"Place_ID X Date\",\"Place_ID.X.Date\"))\n",
    "train_data <- data[1:nrow(train), features, drop = FALSE]\n",
    "test_data <- data[(nrow(train) + 1):nrow(data), features, drop = FALSE]\n",
    "data_train_val <- get_train_val(train_data ,0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33557cf1-87ee-4eca-979f-d074518b5743",
   "metadata": {},
   "source": [
    "#### Plot repartition of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3045fdf2-d8de-4095-a415-b24cd1984a6b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 120,
       "width": 600
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "partition_sizes <- data.frame(\n",
    "  Partition = c(\"Train\", \"Validation\", \"Test\"),\n",
    "  Size = c(nrow(data_train_val$train), nrow(data_train_val$val), nrow(test_data))\n",
    ")\n",
    "\n",
    "# Plot the partition sizes\n",
    "options(repr.plot.width = 10, repr.plot.height = 2)\n",
    "ggplot(partition_sizes, aes(x = \"\", y = Size, fill = Partition)) +\n",
    "  geom_bar(stat = \"identity\", width = 1) +\n",
    "  coord_flip() +\n",
    "  geom_text(aes(label = Size), position = position_stack(vjust = 0.5)) +\n",
    "  theme_minimal() +\n",
    "  labs(title = \"Data Partition Sizes\", x = NULL, y = NULL) +\n",
    "  scale_fill_manual(values = c(\"Train\" = \"cornflowerblue\", \"Validation\" = \"coral\", \"Test\" = \"darkolivegreen3\")) +\n",
    "  theme(\n",
    "    axis.ticks = element_blank(), \n",
    "    axis.text.y = element_blank(),\n",
    "    aspect.ratio = 1/10 # Adjust the aspect ratio to make the plot shorter\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0b05bc-3b61-46a2-a650-030fa3ba8b1f",
   "metadata": {},
   "source": [
    "### 2. Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98632a2d-6512-480c-b679-593df309fd82",
   "metadata": {},
   "source": [
    "#### Data preparation for all models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2620aee-d514-46f9-a0f8-befe665afe8e",
   "metadata": {},
   "source": [
    "###### Input configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1aadee3a-e553-4344-b69d-f2b41586495b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train = get_train_data()\n",
    "test = get_test_data()\n",
    "data <- bind_rows(train, test)\n",
    "data <- na_to_median_by_location(data)\n",
    "#data\n",
    "data <- add_time(data)\n",
    "#data <- add_lag_lead(data,10)\n",
    "features <- setdiff(names(data), c(\"Date\", \"Place_ID.X.Date\"))\n",
    "train_data <- data[1:nrow(train), features, drop = FALSE]\n",
    "test_data <- data[(nrow(train) + 1):nrow(data), features, drop = FALSE]\n",
    "data_train_val <- get_train_val(train_data ,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52c7c8b9-c510-4fd6-83c9-94278fce45ee",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train_x <- data_train_val$train %>% select(-c(target)) %>% as.matrix()\n",
    "train_y <- data_train_val$train$target\n",
    "\n",
    "val_x <- data_train_val$val %>% select(-target) %>% as.matrix()\n",
    "val_y <- data_train_val$val$target\n",
    "\n",
    "# Normalize the features (if necessary)\n",
    "train_x_norm <- scale(train_x)\n",
    "val_x_norm <- scale(val_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef91d51d-8b03-4150-9a73-fbdb66b1c6b4",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e467e73d-4a2c-4f27-8455-5778a4cffc2b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: <Sequential name=sequential, built=False> (of type <class 'keras.src.models.sequential.Sequential'>)",
     "output_type": "error",
     "traceback": [
      "Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: <Sequential name=sequential, built=False> (of type <class 'keras.src.models.sequential.Sequential'>)Traceback:\n",
      "1. create_nn_model(input_shape)",
      "2. keras_model_sequential() %>% layer_dense(units = 128, activation = \"relu\", \n .     input_shape = input_shape) %>% layer_dense(units = 128, activation = \"relu\") %>% \n .     layer_dense(units = 128, activation = \"relu\") %>% layer_dense(units = 128, \n .     activation = \"relu\") %>% layer_dense(units = 128, activation = \"relu\") %>% \n .     layer_dense(units = 1)   # at line 2-8 of file <text>",
      "3. layer_dense(., units = 1)",
      "4. create_layer(keras$layers$Dense, object, list(units = as.integer(units), \n .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n .     name = name, trainable = trainable, weights = weights))",
      "5. layer_dense(., units = 128, activation = \"relu\")",
      "6. create_layer(keras$layers$Dense, object, list(units = as.integer(units), \n .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n .     name = name, trainable = trainable, weights = weights))",
      "7. layer_dense(., units = 128, activation = \"relu\")",
      "8. create_layer(keras$layers$Dense, object, list(units = as.integer(units), \n .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n .     name = name, trainable = trainable, weights = weights))",
      "9. layer_dense(., units = 128, activation = \"relu\")",
      "10. create_layer(keras$layers$Dense, object, list(units = as.integer(units), \n  .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n  .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n  .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n  .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n  .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n  .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n  .     name = name, trainable = trainable, weights = weights))",
      "11. layer_dense(., units = 128, activation = \"relu\")",
      "12. create_layer(keras$layers$Dense, object, list(units = as.integer(units), \n  .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n  .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n  .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n  .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n  .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n  .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n  .     name = name, trainable = trainable, weights = weights))",
      "13. layer_dense(., units = 128, activation = \"relu\", input_shape = input_shape)",
      "14. create_layer(keras$layers$Dense, object, list(units = as.integer(units), \n  .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n  .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n  .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n  .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n  .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n  .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n  .     name = name, trainable = trainable, weights = weights))",
      "15. compose_layer(object, layer)",
      "16. compose_layer.default(object, layer)",
      "17. layer(object, ...)",
      "18. py_call_impl(callable, call_args$unnamed, call_args$named)"
     ]
    }
   ],
   "source": [
    "create_nn_model <- function(input_shape) {\n",
    "  nn_model <- keras_model_sequential() %>%\n",
    "    layer_dense(units = 128, activation = 'relu', input_shape = input_shape) %>%\n",
    "    layer_dense(units = 128, activation = 'relu') %>%\n",
    "    layer_dense(units = 128, activation = 'relu') %>%\n",
    "    layer_dense(units = 128, activation = 'relu') %>%\n",
    "    layer_dense(units = 128, activation = 'relu') %>%\n",
    "    layer_dense(units = 1)\n",
    "  \n",
    "  nn_model %>% compile(\n",
    "    loss = 'mse',  # Mean Squared Error for regression\n",
    "    optimizer = 'adam',  # Adaptive moment estimation\n",
    "    metrics = c('mean_absolute_error')\n",
    "  )\n",
    "  \n",
    "  return(nn_model)\n",
    "}\n",
    "\n",
    "# Create the model\n",
    "input_shape <- ncol(train_x)\n",
    "model <- create_nn_model(input_shape)\n",
    "\n",
    "# Train the model\n",
    "history <- model %>% fit(\n",
    "  train_x_norm, train_y,\n",
    "  epochs = 1000,\n",
    "  batch_size = 32,\n",
    "  validation_split = 0.2\n",
    ")\n",
    "\n",
    "# Make predictions on the validation data\n",
    "predictions <- model %>% predict(val_x_norm)\n",
    "rmse <- sqrt(mean((predictions - val_y)^2))\n",
    "score_nn = rmse\n",
    "print(paste(\"RMSE: \", rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974b8e06",
   "metadata": {},
   "source": [
    "#### Neural Network from Chat GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "357a96a2",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: <Sequential name=sequential_1, built=False> (of type <class 'keras.src.models.sequential.Sequential'>)",
     "output_type": "error",
     "traceback": [
      "Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: <Sequential name=sequential_1, built=False> (of type <class 'keras.src.models.sequential.Sequential'>)Traceback:\n",
      "1. create_nn_model(input_shape)",
      "2. keras_model_sequential() %>% layer_dense(units = 128, activation = \"relu\", \n .     input_shape = input_shape) %>% layer_dense(units = 128, activation = \"relu\") %>% \n .     layer_dense(units = 128, activation = \"relu\") %>% layer_dense(units = 128, \n .     activation = \"relu\") %>% layer_dense(units = 128, activation = \"relu\") %>% \n .     layer_dense(units = 1)   # at line 5-11 of file <text>",
      "3. layer_dense(., units = 1)",
      "4. create_layer(keras$layers$Dense, object, list(units = as.integer(units), \n .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n .     name = name, trainable = trainable, weights = weights))",
      "5. layer_dense(., units = 128, activation = \"relu\")",
      "6. create_layer(keras$layers$Dense, object, list(units = as.integer(units), \n .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n .     name = name, trainable = trainable, weights = weights))",
      "7. layer_dense(., units = 128, activation = \"relu\")",
      "8. create_layer(keras$layers$Dense, object, list(units = as.integer(units), \n .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n .     name = name, trainable = trainable, weights = weights))",
      "9. layer_dense(., units = 128, activation = \"relu\")",
      "10. create_layer(keras$layers$Dense, object, list(units = as.integer(units), \n  .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n  .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n  .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n  .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n  .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n  .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n  .     name = name, trainable = trainable, weights = weights))",
      "11. layer_dense(., units = 128, activation = \"relu\")",
      "12. create_layer(keras$layers$Dense, object, list(units = as.integer(units), \n  .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n  .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n  .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n  .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n  .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n  .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n  .     name = name, trainable = trainable, weights = weights))",
      "13. layer_dense(., units = 128, activation = \"relu\", input_shape = input_shape)",
      "14. create_layer(keras$layers$Dense, object, list(units = as.integer(units), \n  .     activation = activation, use_bias = use_bias, kernel_initializer = kernel_initializer, \n  .     bias_initializer = bias_initializer, kernel_regularizer = kernel_regularizer, \n  .     bias_regularizer = bias_regularizer, activity_regularizer = activity_regularizer, \n  .     kernel_constraint = kernel_constraint, bias_constraint = bias_constraint, \n  .     input_shape = normalize_shape(input_shape), batch_input_shape = normalize_shape(batch_input_shape), \n  .     batch_size = as_nullable_integer(batch_size), dtype = dtype, \n  .     name = name, trainable = trainable, weights = weights))",
      "15. compose_layer(object, layer)",
      "16. compose_layer.default(object, layer)",
      "17. layer(object, ...)",
      "18. py_call_impl(callable, call_args$unnamed, call_args$named)"
     ]
    }
   ],
   "source": [
    "library(keras)\n",
    "\n",
    "# Define the function to create the model\n",
    "create_nn_model <- function(input_shape) {\n",
    "  nn_model <- keras_model_sequential() %>%\n",
    "    layer_dense(units = 128, activation = 'relu', input_shape = input_shape) %>%\n",
    "    layer_dense(units = 128, activation = 'relu') %>%\n",
    "    layer_dense(units = 128, activation = 'relu') %>%\n",
    "    layer_dense(units = 128, activation = 'relu') %>%\n",
    "    layer_dense(units = 128, activation = 'relu') %>%\n",
    "    layer_dense(units = 1)\n",
    "  \n",
    "  nn_model %>% compile(\n",
    "    loss = 'mse',  # Mean Squared Error for regression\n",
    "    optimizer = 'adam',  # Adaptive moment estimation\n",
    "    metrics = c('mean_absolute_error')\n",
    "  )\n",
    "  \n",
    "  return(nn_model)\n",
    "}\n",
    "\n",
    "# Assuming you have train_x, train_y, val_x_norm, val_y, and train_x_norm defined somewhere\n",
    "input_shape <- dim(train_x)[2]  # Adjust based on your data structure\n",
    "model <- create_nn_model(input_shape)\n",
    "\n",
    "# Train the model\n",
    "history <- model %>% fit(\n",
    "  train_x_norm, train_y,\n",
    "  epochs = 1000,\n",
    "  batch_size = 32,\n",
    "  validation_split = 0.2\n",
    ")\n",
    "\n",
    "# Make predictions on the validation data\n",
    "predictions <- model %>% predict(val_x_norm)\n",
    "rmse <- sqrt(mean((predictions - val_y)^2))\n",
    "score_nn <- rmse\n",
    "print(paste(\"RMSE: \", rmse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62039f20-3319-47d9-98cb-2a707f080dc7",
   "metadata": {},
   "source": [
    "#### RSNNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1899b72-42b9-431b-96ac-b5147d439437",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "control <- trainControl(method = \"none\")\n",
    "RSNNS_model <- train(train_x_norm, train_y, method = \"mlp\", trControl = control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bd7a881-1248-4063-bffc-1aa7f190ea98",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Root Mean Squared Error (RMSE): 47.3756663368529\"\n"
     ]
    }
   ],
   "source": [
    "predictions <- predict(RSNNS_model, val_x_norm)\n",
    "rmse <- sqrt(mean((predictions - val_y)^2))\n",
    "score_rsnns = rmse\n",
    "print(paste(\"Root Mean Squared Error (RMSE):\", rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff281522-9aff-4225-8468-f87f2d1eb655",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "874e1537-ea3b-42f5-be24-ffac91f397f5",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "svm_model <- svm(target ~ ., data = data_train_val$train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c266aa1-60b0-49f7-9da7-e19dda4f877e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Root Mean Squared Error (RMSE): 27.258724058156\"\n"
     ]
    }
   ],
   "source": [
    "predictions <- predict(svm_model, val_x)\n",
    "rmse <- sqrt(mean((predictions - val_y)^2))\n",
    "score_svm = rmse\n",
    "print(paste(\"Root Mean Squared Error (RMSE):\", rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48577414-9475-4c8a-a3d0-66797414c2fe",
   "metadata": {},
   "source": [
    "#### Randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "45689dcb-0a1c-4995-9c74-bd10082dfd1f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "rf_model <- randomForest(target ~ ., data = data_train_val$train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec73ef5d-d039-44cd-9a26-ce0fe7e3ced3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Root Mean Squared Error (RMSE): 27.3169107939007\"\n"
     ]
    }
   ],
   "source": [
    "predictions <- predict(rf_model, val_x)\n",
    "rmse <- sqrt(mean((predictions - val_y)^2))\n",
    "score_rf = rmse\n",
    "print(paste(\"Root Mean Squared Error (RMSE):\", rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056d6da8-a628-4565-8b8a-cb680ae66de7",
   "metadata": {},
   "source": [
    "#### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ddd48d2c-46b3-4642-a0e8-76fdf640ec4b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): objet 'score_nn' introuvable\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): objet 'score_nn' introuvable\nTraceback:\n",
      "1. data.frame(Model = c(\"Neural Network\", \"RSNNS\", \"SVM\", \"Random Forest\"), \n .     RMSE = c(score_nn, score_rsnns, score_svm, score_rf))"
     ]
    }
   ],
   "source": [
    "# Create a dataframe with RMSE values\n",
    "rmse_df <- data.frame(\n",
    "  Model = c(\"Neural Network\", \"RSNNS\", \"SVM\", \"Random Forest\"),\n",
    "  RMSE = c(score_nn, score_rsnns, score_svm, score_rf))\n",
    "\n",
    "# Plot RMSE values\n",
    "ggplot(rmse_df, aes(x = Model, y = RMSE, fill = Model)) +\n",
    "  geom_bar(stat = \"identity\") +\n",
    "  theme_minimal() +\n",
    "  ggtitle(\"Model Comparison Based on RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b7650c-b120-4d95-9879-ad1c6ee515d9",
   "metadata": {},
   "source": [
    "### 3. Other model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5231ef-b761-4925-babd-ec065e4f64c3",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a205cf03-fdb8-497e-8d17-ffa3e53dcddd",
   "metadata": {},
   "source": [
    "###### Input configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "639612e6-6a01-405b-9308-a39425a51040",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train = get_train_data()\n",
    "test = get_test_data()\n",
    "data <- bind_rows(train, test)\n",
    "data <- na_to_median_by_location(data)\n",
    "#data\n",
    "data <- add_time(data)\n",
    "#data <- add_lag_lead(data,10)\n",
    "features <- setdiff(names(data), c(\"Date\", \"Place_ID.X.Date\"))\n",
    "train_data <- data[1:nrow(train), features, drop = FALSE]\n",
    "test_data <- data[(nrow(train) + 1):nrow(data), features, drop = FALSE]\n",
    "data_train_val <- get_train_val(train_data ,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ff9c964-4b57-40a1-8d2d-5b0d416ab670",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train_x <- data_train_val$train %>% select(-c(target)) %>% as.matrix()\n",
    "train_y <- data_train_val$train$target\n",
    "\n",
    "val_x <- data_train_val$val %>% select(-target) %>% as.matrix()\n",
    "val_y <- data_train_val$val$target\n",
    "\n",
    "# Normalize the features (if necessary)\n",
    "#train_x_norm <- scale(train_x)\n",
    "#val_x_norm <- scale(val_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1eec9b-e0bc-48c6-8464-948bf464ef95",
   "metadata": {},
   "source": [
    "###### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f5b1c17-2fde-45f9-854c-ca759fc87dfc",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train_x_matrix <- as.matrix(train_x)\n",
    "train_y_vector <- as.numeric(train_y)\n",
    "dtrain <- xgb.DMatrix(data = train_x, label = train_y)\n",
    "\n",
    "xgb_model <- xgb.train( data = dtrain, nrounds = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ade0ece9-f55e-4ef8-bf5e-a5d893e93995",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Root Mean Squared Error (RMSE): 34.4893738911475\"\n"
     ]
    }
   ],
   "source": [
    "dval <- xgb.DMatrix(data = val_x)\n",
    "predictions <- predict(xgb_model, dval)\n",
    "rmse <- sqrt(mean((predictions - val_y)^2))\n",
    "score_xgb = rmse\n",
    "print(paste(\"Root Mean Squared Error (RMSE):\", rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2371badd-dea4-444c-a8af-0ae37d311498",
   "metadata": {},
   "source": [
    "#### LGB model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaf1f54-5119-4874-b752-7d8f8157b460",
   "metadata": {},
   "source": [
    "###### Input configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba40a24c-fb06-4f98-85b2-51d32f0a3c0e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train = get_train_data()\n",
    "test = get_test_data()\n",
    "data <- bind_rows(train, test)\n",
    "data <- na_to_median_by_location(data)\n",
    "#data\n",
    "data <- add_time(data)\n",
    "#data <- add_lag_lead(data,10)\n",
    "features <- setdiff(names(data), c(\"Date\", \"Place_ID.X.Date\"))\n",
    "train_data <- data[1:nrow(train), features, drop = FALSE]\n",
    "test_data <- data[(nrow(train) + 1):nrow(data), features, drop = FALSE]\n",
    "data_train_val <- get_train_val(train_data ,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90496968-784e-48e7-85be-132713544b67",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "train_x <- data_train_val$train %>% select(-c(target)) %>% as.matrix()\n",
    "train_y <- data_train_val$train$target\n",
    "\n",
    "val_x <- data_train_val$val %>% select(-target) %>% as.matrix()\n",
    "val_y <- data_train_val$val$target\n",
    "\n",
    "# Normalize the features (if necessary)\n",
    "#train_x_norm <- scale(train_x)\n",
    "#val_x_norm <- scale(val_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33cde86-13ee-46a6-b702-a95ac90d1844",
   "metadata": {},
   "source": [
    "###### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "706acea6-f9fa-4547-863a-fc0d04847b41",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 18947\n",
      "[LightGBM] [Info] Number of data points in the train set: 24446, number of used features: 79\n",
      "[LightGBM] [Info] Start training from score 59.388464\n"
     ]
    }
   ],
   "source": [
    "dtrain <- lgb.Dataset(data = train_x, label = train_y, free_raw_data = FALSE)\n",
    "dtest <- lgb.Dataset(data = val_x, label = val_y, free_raw_data = FALSE)\n",
    "\n",
    "# Parameters setup for LightGBM\n",
    "params <- list(\n",
    "    objective = \"regression\",\n",
    "    metric = \"rmse\")\n",
    "\n",
    "# Train the LightGBM model with early stopping\n",
    "lgb_model <- lgb.train(\n",
    "  params = params,\n",
    "  data = dtrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d08fdaf2-b172-4bf8-8eb7-95d5c6167482",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Root Mean Squared Error (RMSE): 36.2152714373312\"\n"
     ]
    }
   ],
   "source": [
    "predictions <- predict(lgb_model, val_x)\n",
    "rmse <- sqrt(mean((predictions - val_y)^2))\n",
    "score_lgb = rmse\n",
    "print(paste(\"Root Mean Squared Error (RMSE):\", rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f702d94-b440-4df9-8cb5-6c4e6deb23dd",
   "metadata": {},
   "source": [
    "#### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c83699d2-7c78-4954-8b44-ca94d6929d30",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): objet 'score_nn' introuvable\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): objet 'score_nn' introuvable\nTraceback:\n",
      "1. data.frame(Model = c(\"Neural Network\", \"RSNNS\", \"SVM\", \"Random Forest\", \n .     \"XGBost\", \"Light Gradient Boost\"), RMSE = c(score_nn, score_rsnns, \n .     score_svm, score_rf, score_xgb, score_lgb))"
     ]
    }
   ],
   "source": [
    "# Create a dataframe with RMSE values\n",
    "rmse_df <- data.frame(\n",
    "  Model = c(\"Neural Network\", \"RSNNS\", \"SVM\", \"Random Forest\", \"XGBost\", \"Light Gradient Boost\"),\n",
    "  RMSE = c(score_nn, score_rsnns, score_svm, score_rf, score_xgb, score_lgb))\n",
    "\n",
    "# Plot RMSE values\n",
    "ggplot(rmse_df, aes(x = Model, y = RMSE, fill = Model)) +\n",
    "  geom_bar(stat = \"identity\") +\n",
    "  theme_minimal() +\n",
    "  ggtitle(\"Model Comparison Based on RMSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caa9f76-8c59-4698-a021-7e8bd8ab8dd4",
   "metadata": {},
   "source": [
    "### 4. Zindi completition upload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b9de70-22f4-43c9-addf-955445add789",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28c56024-70a1-4b67-afe0-0c8e730041ce",
   "metadata": {},
   "source": [
    "### 5. ranking of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe29a3a9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'L3_CO_CO_column_number_density'</li><li>'L3_NO2_NO2_slant_column_number_density'</li><li>'L3_CH4_CH4_column_volume_mixing_ratio_dry_air'</li><li>'L3_HCHO_tropospheric_HCHO_column_number_density'</li><li>'u_component_of_wind_10m_above_ground'</li><li>'temperature_2m_above_ground'</li><li>'L3_AER_AI_sensor_altitude'</li><li>'L3_CH4_aerosol_optical_depth'</li><li>'v_component_of_wind_10m_above_ground'</li><li>'L3_HCHO_tropospheric_HCHO_column_number_density_amf'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'L3\\_CO\\_CO\\_column\\_number\\_density'\n",
       "\\item 'L3\\_NO2\\_NO2\\_slant\\_column\\_number\\_density'\n",
       "\\item 'L3\\_CH4\\_CH4\\_column\\_volume\\_mixing\\_ratio\\_dry\\_air'\n",
       "\\item 'L3\\_HCHO\\_tropospheric\\_HCHO\\_column\\_number\\_density'\n",
       "\\item 'u\\_component\\_of\\_wind\\_10m\\_above\\_ground'\n",
       "\\item 'temperature\\_2m\\_above\\_ground'\n",
       "\\item 'L3\\_AER\\_AI\\_sensor\\_altitude'\n",
       "\\item 'L3\\_CH4\\_aerosol\\_optical\\_depth'\n",
       "\\item 'v\\_component\\_of\\_wind\\_10m\\_above\\_ground'\n",
       "\\item 'L3\\_HCHO\\_tropospheric\\_HCHO\\_column\\_number\\_density\\_amf'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'L3_CO_CO_column_number_density'\n",
       "2. 'L3_NO2_NO2_slant_column_number_density'\n",
       "3. 'L3_CH4_CH4_column_volume_mixing_ratio_dry_air'\n",
       "4. 'L3_HCHO_tropospheric_HCHO_column_number_density'\n",
       "5. 'u_component_of_wind_10m_above_ground'\n",
       "6. 'temperature_2m_above_ground'\n",
       "7. 'L3_AER_AI_sensor_altitude'\n",
       "8. 'L3_CH4_aerosol_optical_depth'\n",
       "9. 'v_component_of_wind_10m_above_ground'\n",
       "10. 'L3_HCHO_tropospheric_HCHO_column_number_density_amf'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"L3_CO_CO_column_number_density\"                     \n",
       " [2] \"L3_NO2_NO2_slant_column_number_density\"             \n",
       " [3] \"L3_CH4_CH4_column_volume_mixing_ratio_dry_air\"      \n",
       " [4] \"L3_HCHO_tropospheric_HCHO_column_number_density\"    \n",
       " [5] \"u_component_of_wind_10m_above_ground\"               \n",
       " [6] \"temperature_2m_above_ground\"                        \n",
       " [7] \"L3_AER_AI_sensor_altitude\"                          \n",
       " [8] \"L3_CH4_aerosol_optical_depth\"                       \n",
       " [9] \"v_component_of_wind_10m_above_ground\"               \n",
       "[10] \"L3_HCHO_tropospheric_HCHO_column_number_density_amf\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Deriving the 10 most relevant features from our lgb model\n",
    "importance <- lgb.importance(lgb_model,percentage=TRUE)\n",
    "top_10_features <- head(importance$Feature, 10)\n",
    "top_10_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d192707e",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "col_to_exclude <- setdiff(colnames(data),c(\"Place_ID\", top_10_features)) #keep Place_ID to be able to run get_train_val\n",
    "X<-data[,setdiff(c(top_10_features, \"Place_ID\"), col_to_exclude)]\n",
    "Y<-data[,\"target\"]\n",
    "\n",
    "# to access the values I need to write Y$target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "76b49d5c",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 12</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>L3_CO_CO_column_number_density</th><th scope=col>L3_HCHO_tropospheric_HCHO_column_number_density</th><th scope=col>L3_NO2_NO2_slant_column_number_density</th><th scope=col>L3_CH4_CH4_column_volume_mixing_ratio_dry_air</th><th scope=col>L3_CH4_aerosol_optical_depth</th><th scope=col>L3_AER_AI_sensor_altitude</th><th scope=col>temperature_2m_above_ground</th><th scope=col>u_component_of_wind_10m_above_ground</th><th scope=col>v_component_of_wind_10m_above_ground</th><th scope=col>L3_NO2_tropospheric_NO2_column_number_density</th><th scope=col>Place_ID</th><th scope=col>target</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>0.02108025</td><td>6.388800e-05</td><td>0.0001558203</td><td>1793.794</td><td>0.010579039</td><td>840209.9</td><td>18.51684</td><td>1.996377</td><td>-1.2273949</td><td>1.703769e-05</td><td>010Q650</td><td>38</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>0.02201668</td><td>1.709871e-04</td><td>0.0001968663</td><td>1789.960</td><td>0.015104382</td><td>840772.9</td><td>22.54653</td><td>3.330430</td><td>-1.1881078</td><td>2.138147e-05</td><td>010Q650</td><td>39</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>0.02067673</td><td>1.239003e-04</td><td>0.0001704180</td><td>1789.960</td><td>0.008326672</td><td>841410.7</td><td>27.03103</td><td>5.065727</td><td> 3.5005591</td><td>7.482015e-06</td><td>010Q650</td><td>24</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>0.02120710</td><td>8.075774e-05</td><td>0.0001748593</td><td>1789.960</td><td>0.008326672</td><td>841103.2</td><td>23.97186</td><td>3.004001</td><td> 1.0994678</td><td>2.302473e-05</td><td>010Q650</td><td>49</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>0.03776556</td><td>1.402194e-04</td><td>0.0001415511</td><td>1789.960</td><td>0.008326672</td><td>840763.1</td><td>16.81631</td><td>2.621787</td><td> 2.6705589</td><td>8.744767e-06</td><td>010Q650</td><td>21</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>0.02948608</td><td>9.418034e-05</td><td>0.0001455166</td><td>1789.960</td><td>0.008326672</td><td>840356.8</td><td>19.17489</td><td>2.955603</td><td> 0.9690747</td><td>1.169355e-05</td><td>010Q650</td><td>28</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 12\n",
       "\\begin{tabular}{r|llllllllllll}\n",
       "  & L3\\_CO\\_CO\\_column\\_number\\_density & L3\\_HCHO\\_tropospheric\\_HCHO\\_column\\_number\\_density & L3\\_NO2\\_NO2\\_slant\\_column\\_number\\_density & L3\\_CH4\\_CH4\\_column\\_volume\\_mixing\\_ratio\\_dry\\_air & L3\\_CH4\\_aerosol\\_optical\\_depth & L3\\_AER\\_AI\\_sensor\\_altitude & temperature\\_2m\\_above\\_ground & u\\_component\\_of\\_wind\\_10m\\_above\\_ground & v\\_component\\_of\\_wind\\_10m\\_above\\_ground & L3\\_NO2\\_tropospheric\\_NO2\\_column\\_number\\_density & Place\\_ID & target\\\\\n",
       "  & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t1 & 0.02108025 & 6.388800e-05 & 0.0001558203 & 1793.794 & 0.010579039 & 840209.9 & 18.51684 & 1.996377 & -1.2273949 & 1.703769e-05 & 010Q650 & 38\\\\\n",
       "\t2 & 0.02201668 & 1.709871e-04 & 0.0001968663 & 1789.960 & 0.015104382 & 840772.9 & 22.54653 & 3.330430 & -1.1881078 & 2.138147e-05 & 010Q650 & 39\\\\\n",
       "\t3 & 0.02067673 & 1.239003e-04 & 0.0001704180 & 1789.960 & 0.008326672 & 841410.7 & 27.03103 & 5.065727 &  3.5005591 & 7.482015e-06 & 010Q650 & 24\\\\\n",
       "\t4 & 0.02120710 & 8.075774e-05 & 0.0001748593 & 1789.960 & 0.008326672 & 841103.2 & 23.97186 & 3.004001 &  1.0994678 & 2.302473e-05 & 010Q650 & 49\\\\\n",
       "\t5 & 0.03776556 & 1.402194e-04 & 0.0001415511 & 1789.960 & 0.008326672 & 840763.1 & 16.81631 & 2.621787 &  2.6705589 & 8.744767e-06 & 010Q650 & 21\\\\\n",
       "\t6 & 0.02948608 & 9.418034e-05 & 0.0001455166 & 1789.960 & 0.008326672 & 840356.8 & 19.17489 & 2.955603 &  0.9690747 & 1.169355e-05 & 010Q650 & 28\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 12\n",
       "\n",
       "| <!--/--> | L3_CO_CO_column_number_density &lt;dbl&gt; | L3_HCHO_tropospheric_HCHO_column_number_density &lt;dbl&gt; | L3_NO2_NO2_slant_column_number_density &lt;dbl&gt; | L3_CH4_CH4_column_volume_mixing_ratio_dry_air &lt;dbl&gt; | L3_CH4_aerosol_optical_depth &lt;dbl&gt; | L3_AER_AI_sensor_altitude &lt;dbl&gt; | temperature_2m_above_ground &lt;dbl&gt; | u_component_of_wind_10m_above_ground &lt;dbl&gt; | v_component_of_wind_10m_above_ground &lt;dbl&gt; | L3_NO2_tropospheric_NO2_column_number_density &lt;dbl&gt; | Place_ID &lt;chr&gt; | target &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 0.02108025 | 6.388800e-05 | 0.0001558203 | 1793.794 | 0.010579039 | 840209.9 | 18.51684 | 1.996377 | -1.2273949 | 1.703769e-05 | 010Q650 | 38 |\n",
       "| 2 | 0.02201668 | 1.709871e-04 | 0.0001968663 | 1789.960 | 0.015104382 | 840772.9 | 22.54653 | 3.330430 | -1.1881078 | 2.138147e-05 | 010Q650 | 39 |\n",
       "| 3 | 0.02067673 | 1.239003e-04 | 0.0001704180 | 1789.960 | 0.008326672 | 841410.7 | 27.03103 | 5.065727 |  3.5005591 | 7.482015e-06 | 010Q650 | 24 |\n",
       "| 4 | 0.02120710 | 8.075774e-05 | 0.0001748593 | 1789.960 | 0.008326672 | 841103.2 | 23.97186 | 3.004001 |  1.0994678 | 2.302473e-05 | 010Q650 | 49 |\n",
       "| 5 | 0.03776556 | 1.402194e-04 | 0.0001415511 | 1789.960 | 0.008326672 | 840763.1 | 16.81631 | 2.621787 |  2.6705589 | 8.744767e-06 | 010Q650 | 21 |\n",
       "| 6 | 0.02948608 | 9.418034e-05 | 0.0001455166 | 1789.960 | 0.008326672 | 840356.8 | 19.17489 | 2.955603 |  0.9690747 | 1.169355e-05 | 010Q650 | 28 |\n",
       "\n"
      ],
      "text/plain": [
       "  L3_CO_CO_column_number_density\n",
       "1 0.02108025                    \n",
       "2 0.02201668                    \n",
       "3 0.02067673                    \n",
       "4 0.02120710                    \n",
       "5 0.03776556                    \n",
       "6 0.02948608                    \n",
       "  L3_HCHO_tropospheric_HCHO_column_number_density\n",
       "1 6.388800e-05                                   \n",
       "2 1.709871e-04                                   \n",
       "3 1.239003e-04                                   \n",
       "4 8.075774e-05                                   \n",
       "5 1.402194e-04                                   \n",
       "6 9.418034e-05                                   \n",
       "  L3_NO2_NO2_slant_column_number_density\n",
       "1 0.0001558203                          \n",
       "2 0.0001968663                          \n",
       "3 0.0001704180                          \n",
       "4 0.0001748593                          \n",
       "5 0.0001415511                          \n",
       "6 0.0001455166                          \n",
       "  L3_CH4_CH4_column_volume_mixing_ratio_dry_air L3_CH4_aerosol_optical_depth\n",
       "1 1793.794                                      0.010579039                 \n",
       "2 1789.960                                      0.015104382                 \n",
       "3 1789.960                                      0.008326672                 \n",
       "4 1789.960                                      0.008326672                 \n",
       "5 1789.960                                      0.008326672                 \n",
       "6 1789.960                                      0.008326672                 \n",
       "  L3_AER_AI_sensor_altitude temperature_2m_above_ground\n",
       "1 840209.9                  18.51684                   \n",
       "2 840772.9                  22.54653                   \n",
       "3 841410.7                  27.03103                   \n",
       "4 841103.2                  23.97186                   \n",
       "5 840763.1                  16.81631                   \n",
       "6 840356.8                  19.17489                   \n",
       "  u_component_of_wind_10m_above_ground v_component_of_wind_10m_above_ground\n",
       "1 1.996377                             -1.2273949                          \n",
       "2 3.330430                             -1.1881078                          \n",
       "3 5.065727                              3.5005591                          \n",
       "4 3.004001                              1.0994678                          \n",
       "5 2.621787                              2.6705589                          \n",
       "6 2.955603                              0.9690747                          \n",
       "  L3_NO2_tropospheric_NO2_column_number_density Place_ID target\n",
       "1 1.703769e-05                                  010Q650  38    \n",
       "2 2.138147e-05                                  010Q650  39    \n",
       "3 7.482015e-06                                  010Q650  24    \n",
       "4 2.302473e-05                                  010Q650  49    \n",
       "5 8.744767e-06                                  010Q650  21    \n",
       "6 1.169355e-05                                  010Q650  28    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "XwithTarget <- cbind(X, Target=Y)\n",
    "head(XwithTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "25f71efd",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>38</li><li>39</li><li>24</li><li>49</li><li>21</li><li>28</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 38\n",
       "\\item 39\n",
       "\\item 24\n",
       "\\item 49\n",
       "\\item 21\n",
       "\\item 28\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 38\n",
       "2. 39\n",
       "3. 24\n",
       "4. 49\n",
       "5. 21\n",
       "6. 28\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 38 39 24 49 21 28"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(Y$target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "7b1d17a9",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in self$set_field(field_name = names(p), data = p[[1L]]): l'objet 'list' ne peut être converti automatiquement en un type 'double'\n",
     "output_type": "error",
     "traceback": [
      "Error in self$set_field(field_name = names(p), data = p[[1L]]): l'objet 'list' ne peut être converti automatiquement en un type 'double'\nTraceback:\n",
      "1. lgb.train(params = params, train_test)",
      "2. data$construct()",
      "3. self$set_field(field_name = names(p), data = p[[1L]])"
     ]
    }
   ],
   "source": [
    "test_model <- lgb.train(params = params, train_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c200a1d",
   "metadata": {},
   "source": [
    "#### Create a function that creates LGB models with $X^{-i}$ features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "36f182f7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "create_minus_i_model <- function(X, Y, i) {\n",
    "#First step is to create the X-i data frame to be able to create our lgb model\n",
    "    X_minus_i <- X[, -i]\n",
    "    data_for_train <- cbind(X_minus_i, Target = Y)\n",
    "    \n",
    "    rmse_list <- vector(\"numeric\", 50)\n",
    "\n",
    "    for (j in 1:50) {\n",
    "    #split the data in train and validation data\n",
    "    XminusI_train_val <- get_train_val(data_for_train, 0.8)\n",
    "\n",
    "    train_X <- XminusI_train_val$train %>% select(-c(target)) %>% as.matrix()\n",
    "    train_Y <- XminusI_train_val$train$target\n",
    "\n",
    "    val_X <- XminusI_train_val$val %>% select(-target) %>% as.matrix()\n",
    "    val_Y <- XminusI_train_val$val$target\n",
    "\n",
    "   \n",
    "    #Convert Data to LGB Dataset Format\n",
    "    d_train <- lgb.Dataset(data = as.matrix(train_X), label = train_Y)\n",
    "    d_val <- lgb.Dataset(data = as.matrix(val_X), label = val_Y, free_raw_data = FALSE)\n",
    "    \n",
    "    #set parameters\n",
    "    params <- list(\n",
    "        objective = \"regression\",\n",
    "        metric = \"rmse\",\n",
    "        force_col_wise=TRUE,\n",
    "        num_leaves=50,\n",
    "        max_depth = -1\n",
    "        )\n",
    "    \n",
    "    #train the model\n",
    "    model_i <- lgb.train(params = params,\n",
    "        data = d_train,\n",
    "        nrounds = 200,\n",
    "        early_stopping_rounds = 10,\n",
    "        valids = list(test = d_val),\n",
    "        verbose = 0\n",
    "        )\n",
    "    \n",
    "    pred <- predict(model_i, as.matrix(val_X))\n",
    "    # For regression\n",
    "    rmse <- sqrt(mean((pred - val_Y)^2))\n",
    "    \n",
    "    rmse_list[j] <- round(rmse, 4)\n",
    "    }\n",
    "\n",
    "    mean_rmse <- mean(rmse_list)\n",
    "    return(round(mean_rmse, 4))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e88fcc2b",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "32.694"
      ],
      "text/latex": [
       "32.694"
      ],
      "text/markdown": [
       "32.694"
      ],
      "text/plain": [
       "[1] 32.694"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_minus_i_model(X, Y, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "858e5e6f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "test_every_i <- function(X, Y){\n",
    "#1st Step: Create lgb Model using all parameters of X,\n",
    "#2nd Step: get rmsd de ce model\n",
    "#3rd Step: iterate over every i and compute the rmse for each value of X^(-i)\n",
    "# Stock in a list a tuple of every i and its computed rmse\n",
    "#4th Step: compare the rmse of every iteration to the one generated from X\n",
    "# Rank in order of predictive power\n",
    "\n",
    "# 1st STEP\n",
    "rmse_list <- vector(\"numeric\", 50)\n",
    "for (j in 1:50) {\n",
    "data1 <- cbind(X, Target = Y)\n",
    "data_train_val <- get_train_val(data1, 0.8)\n",
    "\n",
    "train_X <- data_train_val$train %>% select(-c(target)) %>% as.matrix()\n",
    "train_Y <- data_train_val$train$target\n",
    "\n",
    "    val_X <- data_train_val$val %>% select(-target) %>% as.matrix()\n",
    "    val_Y <- data_train_val$val$target\n",
    "\n",
    "   \n",
    "    #Convert Data to LGB Dataset Format\n",
    "    d_train <- lgb.Dataset(data = as.matrix(train_X), label = train_Y)\n",
    "    d_val <- lgb.Dataset(data = as.matrix(val_X), label = val_Y, free_raw_data = FALSE)\n",
    "    \n",
    "    #set parameters\n",
    "    params <- list(\n",
    "        objective = \"regression\",\n",
    "        metric = \"rmse\",\n",
    "        force_col_wise=TRUE,\n",
    "        num_leaves=50,\n",
    "        max_depth = -1\n",
    "        )\n",
    "    \n",
    "    #train the model\n",
    "    model_i <- lgb.train(params = params,\n",
    "        data = d_train,\n",
    "        nrounds = 200,\n",
    "        early_stopping_rounds = 10,\n",
    "        valids = list(test = d_val), #Ask Emile about this param\n",
    "        verbose = 0\n",
    "        )\n",
    "    \n",
    "    pred <- predict(model_i, as.matrix(val_X))\n",
    "    # For regression\n",
    "    rmse <- sqrt(mean((pred - val_Y)^2))\n",
    "    rmse_list[j] <- round(rmse, 4)\n",
    "    }\n",
    "\n",
    "\n",
    "    mean_rmse <- mean(rmse_list)\n",
    "    return(round(mean_rmse, 4))\n",
    "    \n",
    "\n",
    "    # 2nd Step\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8dd5abbb",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "32.4779"
      ],
      "text/latex": [
       "32.4779"
      ],
      "text/markdown": [
       "32.4779"
      ],
      "text/plain": [
       "[1] 32.4779"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_every_i(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9e2c9032",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] \"L3_CO_CO_column_number_density\"                 \n",
      " [2] \"L3_NO2_NO2_slant_column_number_density\"         \n",
      " [3] \"L3_HCHO_tropospheric_HCHO_column_number_density\"\n",
      " [4] \"L3_CH4_CH4_column_volume_mixing_ratio_dry_air\"  \n",
      " [5] \"L3_AER_AI_sensor_altitude\"                      \n",
      " [6] \"temperature_2m_above_ground\"                    \n",
      " [7] \"L3_NO2_tropospheric_NO2_column_number_density\"  \n",
      " [8] \"L3_CO_sensor_altitude\"                          \n",
      " [9] \"L3_HCHO_HCHO_slant_column_number_density\"       \n",
      "[10] \"u_component_of_wind_10m_above_ground\"           \n"
     ]
    }
   ],
   "source": [
    "#Deriving the 10 most relevant features from the rf_model\n",
    "importance_rf <- importance(rf_model)\n",
    "sorted_importance_rf <- sort(importance_rf[, \"IncNodePurity\"], decreasing = TRUE)\n",
    "top_rf_features <- names(sorted_importance_rf)[1:10]\n",
    "print(top_rf_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac6ad1e-0f96-4efa-a120-ac5b7e349508",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "526ab457-de89-41be-a558-209da763fe77",
   "metadata": {},
   "source": [
    "## Competition results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d84b16f-eb4a-4fae-aab9-bff2070fadc3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "371e57bd-54df-4344-b023-ad517813a8ab",
   "metadata": {},
   "source": [
    "## Further implementations to increase the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cc8500-0846-481f-ae0c-56984757609f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
